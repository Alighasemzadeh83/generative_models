{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "g5dPBdpJ1BzF",
        "2e0uWIt4o3YG",
        "N5fjCsvcq4DF",
        "6l6t-Ht02XoY",
        "eeq6mamSl7hJ",
        "zS7b9Blpvu7j",
        "kS-LvEPiCal2",
        "vAlcZL193jcd"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Models PHW4: Energy-Based Models\n",
        "\n",
        "Name:\n",
        "\n",
        "Student ID:"
      ],
      "metadata": {
        "id": "7s1A4MiYjfEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "g5dPBdpJ1BzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGgRR8AijeMB"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\"cuda\" if torch.cuda.is_available()\n",
        "          else \"mps\" if torch.backends.mps.is_available()\n",
        "          else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2FeUELgmpi6",
        "outputId": "3639b659-7548-46e9-b831-a56752919d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset (10 points)"
      ],
      "metadata": {
        "id": "2e0uWIt4o3YG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the `MNIST` dataset and normalize the images between -1 and 1 as this makes the implementation easier."
      ],
      "metadata": {
        "id": "EvjtjfxKpB8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define transformations and set the batch size\n",
        "transform = ...\n",
        "\n",
        "batch_size = ...\n",
        "\n",
        "# TODO: Load train and test datasets\n",
        "trainset = ...\n",
        "testset = ...\n",
        "\n",
        "# TODO: Load the train and test loaders\n",
        "trainloader = ...\n",
        "testloader = ..."
      ],
      "metadata": {
        "id": "2wXlvhSEo5Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langevin Dynamics (20 points)"
      ],
      "metadata": {
        "id": "N5fjCsvcq4DF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Langevin dynamics in our case starts with a randomly initialized $x_0$ and then uses the information about the landscape of the energy function\n",
        "(i.e., the gradient) to seek for new $x$, that is:\n",
        "$$x_{t+1} = x_{t} + \\alpha \\nabla_{x_t}\\text{LogSumExp} \\left[f_{\\theta} (x) \\right] + \\sigma \\cdot \\epsilon$$\n",
        "\n",
        "where $\\alpha, \\sigma > 0$ and $\\epsilon \\sim \\mathcal{N}(0, I)$. The Langevin dynamics could be seen as the stochastic gradient descent in the observable space with a small Gaussian noise added at each step.\n",
        "\n",
        "Our goal is to run the Langevin dynamics for $\\eta$ iterations with the steps size $\\alpha$ and the noise level equal $\\sigma$."
      ],
      "metadata": {
        "id": "PLqE4vRft9ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def energy_gradient(model, x):\n",
        "    # TODO: Set model to evaluation mode\n",
        "\n",
        "    # TDOO: Copy the original data and make it require gradients\n",
        "\n",
        "    # TODO: Calculate the gradient\n",
        "\n",
        "    # TODO: Set model to training mode\n",
        "\n",
        "    # TODO: Return the gradients\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "7lk8sE5LrePX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def langevin_dynamics_step(model, x, alpha, sigma):\n",
        "    # TODO: Calculate gradient w.r.t. x\n",
        "\n",
        "    # TODO: Sample epsilon ~ Normal(0, I)\n",
        "\n",
        "    # TODO: Generatae a new sample\n",
        "\n",
        "    # TODO: Return the new sample\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "FX_lMoJHq68R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling (15 points)"
      ],
      "metadata": {
        "id": "6l6t-Ht02XoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, eta, alpha, sigma):\n",
        "    # TODO: Sample x0 from uniform [-1, +1]\n",
        "\n",
        "    # TODO: Run Langevin Dynamics Î· times\n",
        "\n",
        "    # TODO: Return the result\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "LPgShok5xGpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss (15 points)"
      ],
      "metadata": {
        "id": "eeq6mamSl7hJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate our model using the following objective:\n",
        "\n",
        "$$\\mathcal{L} = \\mathcal{L}_\\text{clf}(\\theta) + \\mathcal{L}_\\text{gen}(\\theta)$$\n",
        "\n",
        "Where $\\mathcal{L}_\\text{clf}(\\theta)$ is the cross-entropy loss and $\\mathcal{L}_\\text{gen}(\\theta)$ is an approximation to the log-marginal distribution over images (for example the LogSumExp loss)."
      ],
      "metadata": {
        "id": "ZrBVD0wXDkQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(model, eta, alpha, sigma, x, y_pred, y_true):\n",
        "    # TODO: Calculate the discriminative loss: the cross-entropy\n",
        "\n",
        "    # TODO: Calculate the generative loss: E(x) - E(x_sample)\n",
        "\n",
        "    # TODO: Return the total loss\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "FYv-rIgfnC63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network (10 points)"
      ],
      "metadata": {
        "id": "zS7b9Blpvu7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the neural network that specifies the energy function.\n",
        "The inputs should be images and the outputs must be the classes.\n",
        "Don't forget to use appropriate activation functions!"
      ],
      "metadata": {
        "id": "Qo88sgOOBluK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnergyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        pass"
      ],
      "metadata": {
        "id": "s1m6TTQC2tO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize (15 points)"
      ],
      "metadata": {
        "id": "kS-LvEPiCal2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the following functions to be able to visualize real and generated images."
      ],
      "metadata": {
        "id": "VyAF2kMCCc_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_real(loader):\n",
        "    pass\n",
        "\n",
        "\n",
        "def visualize_generated(model, eta, alpha, sigma, loader):\n",
        "    pass"
      ],
      "metadata": {
        "id": "YvdUh2Z3Cjp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training (15 points)"
      ],
      "metadata": {
        "id": "vAlcZL193jcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the evaluation and training functions. Make sure you track the loss and plot it to analyze possible issues."
      ],
      "metadata": {
        "id": "IJgLdcBDB6ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_ebm(model, loader, eta, alpha, sigma):\n",
        "    # TODO: Evaluate the model on the loader\n",
        "\n",
        "    pass\n",
        "\n",
        "def train_ebm(model, optimizer, loader, epochs, eta, alpha, sigma):\n",
        "    # TODO: Train the model on the loader\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "9yRZ5CQS3kcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the optimizer and train your model."
      ],
      "metadata": {
        "id": "H8jTL0ITB91r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train your EBM\n"
      ],
      "metadata": {
        "id": "cDq0di2LoG5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training curve."
      ],
      "metadata": {
        "id": "ofaGc0iUFtRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot loss over epochs\n"
      ],
      "metadata": {
        "id": "alI4ANT4Fvd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now visualize generated samples. (You can visualize images every few epochs to see the evolution of your network)"
      ],
      "metadata": {
        "id": "xHa0IHZoFZM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Generate and visualize images\n"
      ],
      "metadata": {
        "id": "cotKvjLmFbb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your resutls aren't great you can tune the hyperparameters to get better results or alternatively you can modify the dataset (resize, ...)to make it easier to learn the energy function."
      ],
      "metadata": {
        "id": "ELkEM8eyFi8X"
      }
    }
  ]
}